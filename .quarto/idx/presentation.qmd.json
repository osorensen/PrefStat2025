{"title":"Bayesian Inference with the Mallows Model","markdown":{"yaml":{"title":"Bayesian Inference with the Mallows Model","author":"Øystein Sørensen","format":{"revealjs":{"theme":"serif","echo":true}},"engine":"knitr","filters":["webr"],"editor":"source","bibliography":"references.bib"},"headingText":"Learning goals","containsRefs":false,"markdown":"\n\n\n- Bayesian Mallows model [@vitelliProbabilisticPreferenceLearning2017]\n- `BayesMallows` [@sorensenBayesMallowsPackageBayesian2020]\n- Computational algorithms [@vitelliProbabilisticPreferenceLearning2017]\n- Non-transitive preferences [@crispinoBayesianMallowsApproach2019]\n\n\n## R setup\n\n```{r, message=FALSE}\nlibrary(tidyverse)\ntheme_set(theme_bw())\ntheme_update(panel.grid = element_blank())\nlibrary(BayesMallows)\nlibrary(parallel)\n```\n\n# Bayesian Mallows model\n\n## Data-generating distribution\n\nRanking $r$ generated by\n\n$$\np\\left(r | \\theta\\right) = \\frac{\\exp\\left\\{ - \\left(\\alpha /m\\right) d\\left(r, \\rho\\right)\\right\\}}{Z\\left(\\alpha \\right)} \n$$\n\nwith support $\\mathcal{P}_{m}$ and $\\theta = \\{\\alpha, \\rho\\}$.\n\n## Data-generating distribution\n\n- Try out different $\\alpha$ and $\\rho$:\n\n```{webr-r}\nset.seed(12)\nsample_mallows(rho0 = 1:5, alpha0 = 2, n_samples = 4)\n```\n\n\n## Bayesian inference in a nutshell\n\n- Parameters of interest $\\theta$.\n\n- Prior distribution $\\pi(\\theta)$.\n\n- Likelihood $p(\\text{data} | \\theta)$.\n\n. . .\n\n- Posterior \n\n$$\np(\\theta | \\text{data}) = \\frac{\\pi(\\theta) p(\\text{data} | \\theta)}{p(\\text{data})}\n$$ \n\n## Priors for scale parameter\n\n-   @crispinoBayesianMallowsApproach2019:\n\n$$\n\\pi\\left(\\alpha\\right) \\propto \\alpha^{\\gamma-1} \\exp\\{-\\lambda \\alpha\\}, ~ \\alpha \\in [0, \\infty)\n$$\n\n-   @vitelliProbabilisticPreferenceLearning2017, special case $\\gamma=1$.\n\n## Gamma prior\n\n$\\gamma$ is the *shape* and $\\lambda$ is the *rate*.\n\n```{r, echo=FALSE}\ncrossing(\n  alpha = seq(from = 0, to = 3, by = .1),\n  rate = c(.1, 1),\n  shape = c(1, 2)\n) %>% \n  mutate(prob = dgamma(alpha, rate = rate, shape = shape)) %>% \n  ggplot(aes(x = alpha, y = prob, group = interaction(rate, shape),\n             color = factor(rate), linetype = factor(shape))) +\n  geom_line() + \n  ggthemes::scale_color_colorblind() +\n  labs(color = \"Rate\", linetype = \"Shape\") + \n  xlab(expression(alpha)) + \n  ylab(\"Prior density\")\n```\n\n## Prior for modal ranking\n\n-   Uniform distribution on $\\mathcal{P}_{m}$ most natural.\n-   Example, all having prior mass 1/6:\n\n```{webr-r}\nlibrary(e1071)\npermutations(3)\n```\n\n## Posterior distributions {.smaller}\n\n::: incremental\n-   Prior: $\\pi(\\alpha, \\rho) \\propto \\alpha^{\\gamma-1} \\exp\\{-\\lambda \\alpha\\}$ with support $\\mathbb{R}_{+} \\times \\mathcal{P}_{m}$\n\n-   Likelihood $$\n    \\prod_{i=1}^{N} p(r_{i} | \\alpha, \\rho) = \\frac{\\exp\\left\\{-\\left(\\alpha/m\\right) \\sum_{i=1}^{N} d\\left(r_{i}, \\rho\\right)\\right\\}}{Z\\left(\\alpha\\right)^{N}}\n    $$\n\n-   Posterior $$\n    P(\\alpha, \\rho | \\text{data}) \\propto \\frac{\\alpha^{\\gamma-1}\\exp\\left\\{-\\left(\\alpha/m\\right) \\left[\\lambda +\\sum_{i=1}^{N} d\\left(r_{i}, \\rho\\right) \\right]\\right\\}}{Z\\left(\\alpha\\right)^{N}} \n    $$\n    with support $\\mathbb{R}_{+} \\times \\mathcal{P}_{m}$.\n:::\n\n# Computation part I\n\n## Metropolis-Hastings {.smaller}\n\nGoal: obtain samples from $p(\\theta | r_{1:N})$.\n\n::: incremental\n1.  Initialize by picking an initial state $\\theta_{0}$.\n2.  Iterate for $t=0,1,2,\\dots$\n    a.  *Generate* a random candidate $\\theta'$ from proposal distribution $g(\\theta' | \\theta_{t})$.\n    b.  Calculate acceptance probability $$\n         A\\left(\\theta', \\theta_{t}\\right) = \\text{min}\\left\\{1, \\frac{p(\\theta')}{p(\\theta_{t})}\\frac{g(\\theta_{t}|\\theta')}{g(\\theta' | \\theta_{t})}\\right\\} \n         $$\n    c.  Set $\\theta_{t+1}=\\theta'$ with probability $A(\\theta',\\theta_{t})$. Otherwise set $\\theta_{t+1} = \\theta_{t}$.\n:::\n\n. . .\n\nUnder certain assumptions the collection $\\{\\theta_{0},\\theta_{1},\\dots\\}$ will approximate a sample from $p(\\theta)$.\n\n## Metropolis-Hastings for Mallows {.smaller}\n\n::: incremental\n-   Parameters $\\alpha$ and $\\rho$ can be dealt with one at a time.\n-   Acceptance probability $A(\\rho',\\rho_{t})$ for proposal $\\rho'$: $$\n    \\text{min}\\left\\{1, \\exp\\left\\{-\\left(\\alpha_{t}/m\\right) \\left[d\\left(r_{i},\\rho'\\right) - d\\left(r_{i},\\rho_{t}\\right)\\right]\\right\\} \\frac{g\\left(\\rho_{t}|\\rho'\\right)}{g\\left(\\rho'|\\rho_{t}\\right)}\\right\\}\n    $$\n-   Acceptance probability $A(\\alpha',\\alpha_{t})$ for proposal $\\alpha'$: $$\n    \\text{min}\\left\\{1, \\frac{\\left(\\alpha'\\right)^{\\gamma-1} Z\\left(\\alpha_{t}\\right)^{N}}{\\alpha_{t}^{\\gamma-1} Z\\left(\\alpha'\\right)^{N}} \\exp\\left\\{-\\frac{\\alpha'-\\alpha_{t}}{m}\\left[\\lambda+\\sum_{i=1}^{N}d\\left(r_{i},\\rho_{t}\\right)\\right]\\right\\}  \\frac{g\\left(\\alpha_{t} | \\alpha'\\right)}{g\\left(\\alpha'|\\alpha_{t}\\right)}\\right\\} \n    $$\n:::\n\n## Proposal for $\\alpha$ {.smaller}\n\n::: incremental\n-   $g(\\alpha'|\\alpha_{t})$ should have support on $\\mathbb{R}_{+}$ for efficiency.\n\n-   @vitelliProbabilisticPreferenceLearning2017 and `BayesMallows` use lognormal distribution $$\n    g\\left(\\alpha' | \\alpha_{t}\\right) \\propto \\frac{\\exp\\left\\{-\\left(\\ln \\alpha' - \\ln \\alpha_{t}\\right) / (2 \\sigma^{2})\\right\\}}{\\alpha' \\sigma}\n    $$\n\n-   Ratio becomes $$\n    \\frac{g\\left(\\alpha_{t} | \\alpha'\\right)}{g\\left(\\alpha' | \\alpha_{t}\\right)} = \\frac{\\alpha'}{\\alpha_{t}}\n    $$\n\n-   Acceptance probability $$\n    \\text{min}\\left\\{1, \\frac{\\left(\\alpha'\\right)^{\\gamma} Z\\left(\\alpha_{t}\\right)^{N}}{\\alpha_{t}^{\\gamma} Z\\left(\\alpha'\\right)^{N}} \\exp\\left\\{-\\frac{\\alpha'-\\alpha_{t}}{m}\\left[\\lambda+\\sum_{i=1}^{N}d\\left(r_{i},\\rho_{t}\\right)\\right]\\right\\} \\right\\} \n    $$\n:::\n\n## Proposal for $\\rho$\n\n::: incremental\n-   Key issue: $\\rho' \\in \\mathcal{P}_{m}$.\n\n-   Leap-and-shift [@vitelliProbabilisticPreferenceLearning2017] proposal; swap proposal [@crispinoBayesianMallowsApproach2019].\n\n-   Symmetry $g(\\rho' | \\rho_{t}) = g(\\rho_{t} | \\rho')$, always for swap, for leap-and-shift with leap size 1.\n\n-   Acceptance probability under symmetry $$\n    \\text{min}\\left\\{1, \\exp\\left\\{-\\frac{\\alpha_{t}}{m} \\left[d\\left(r_{i},\\rho'\\right) - d\\left(r_{i},\\rho_{t}\\right)\\right]\\right\\}\\right\\}\n    $$\n:::\n\n# Potato data\n\n---\n\n![](figures/potato.png){fig-align=\"center\"}\n\n## Potato data\n\n```{r}\npotato_visual\n```\n\n\n## Convergence diagnostics\n\n```{r}\ncl <- makeCluster(4)\nmod <- compute_mallows(\n  data = setup_rank_data(rankings = potato_visual), \n  compute_options = set_compute_options(nmc = 300), \n  cl = cl)\nstopCluster(cl)\n```\n\n## Convergence diagnostics\n\n```{r}\nassess_convergence(mod) + scale_color_discrete(guide = \"none\")\n```\n\n\n\n## Convergence diagnostics\n\n```{r, fig.align='center'}\ncl <- makeCluster(4)\nmod <- compute_mallows(\n  data = setup_rank_data(rankings = potato_visual), \n  compute_options = set_compute_options(nmc = 5000), \n  cl = cl)\nstopCluster(cl)\n```\n\n## Convergence diagnostics\n\n```{r}\nassess_convergence(mod) + scale_color_discrete(guide = \"none\")\n```\n\n## Convergence diagnostics\n\n```{r, message=TRUE}\nassess_convergence(mod, parameter = \"rho\")\n```\n\n# Studying the posteriors\n\n## Posteriors\n\n```{r}\nburnin(mod) <- 2500\nplot(mod)\n```\n\n## Posteriors\n\n```{r}\nplot(mod, parameter = \"rho\", items = 1:4)\n```\n\n## CP consensus\n\nCumulative probability consensus:\n\n- First select the item which has the maximum a posteriori marginal probability of being ranked 1st\n- Then select the item which has the maximum a posteriori marginal posterior probability of being ranked 1st or 2nd among the remaining ones.\n- etc.\n\n## CP consensus\n\n```{r}\ncompute_consensus(mod)\n```\n\n# Partial rankings and preferences\n\n## Top-3 rankings\n\n-   Top-3 rankings: $$\n    r_{i} = (\\cdot , 1, \\cdot, \\cdot, 3, 2)\n    $$\n\n-   Possible complete rankings: $$\n    (4, 1, 5, 6, 3, 2), (4, 1, 6, 5, 3, 2), \\\\\n    (5, 1, 4, 6, 3, 2), (5, 1, 6, 4, 3, 2), \\\\\n    (6, 1, 4, 5, 3, 2), (6, 1, 5, 4, 3, 2)\n    $$\n\n## Pairwise preferences\n\n-   Observation $(3 \\prec 2), (2 \\prec 1)$\n\n. . .\n\n```{webr-r}\nprefs <- data.frame(\n  assessor = 1, bottom_item = c(2, 3), top_item = c(1, 2))\nget_transitive_closure(\n  setup_rank_data(preferences = prefs, n_items = 4))\n```\n\n. . .\n\n-   Possible complete rankings (with 4 items) $$\n    (4, 1, 2, 3), (1, 4, 2, 3), (1, 2, 4, 3), (1, 2, 3, 4)\n    $$\n\n## Posteriors {.smaller}\n\n:::{.incremental}\n-   Partial ranking or pairwise preferences in $y_{i}$ generate a constraint set $\\mathcal{S}_{i}$.\n\n-   Marginal likelihood $$\n    \\prod_{i=1}^{N} p\\left(y_{i} | \\alpha, \\rho\\right) = \\frac{1}{Z\\left(\\alpha\\right)} \\prod_{i=1}^{N} \\sum_{r_{i} \\in \\mathcal{S}_{i}} \\exp\\left\\{-\\left(\\alpha /m\\right)  d\\left(r_{i}, \\rho\\right)\\right\\}\n    $$\n\n-   Marginal posterior $$\n    p\\left(\\alpha, \\rho | \\text{data}\\right) =  \\frac{\\alpha^{\\gamma -1 } \\exp\\left\\{-\\lambda \\alpha\\right\\}}{Z\\left(\\alpha\\right)} \\prod_{i=1}^{N} \\sum_{r_{i} \\in \\mathcal{S}_{i}} \\exp\\left\\{-\\left(\\alpha /m\\right) d\\left(r_{i}, \\rho\\right)\\right\\}\n    $$\n\n-   Complete data: special case with $\\mathcal{S}_{i} = \\{y_{i}\\}$.\n:::\n\n## Metropolis-Hastings\n\n:::{.incremental}\n-   Need to add sampling of $r_{i}$.\n-   Cost of $M$ iteration now becomes $\\mathcal{O}(NM)$, up from $\\mathcal{O}(M)$ with complete data.\n-   Proposing $r_{i}$ on $\\mathcal{S}_{i}$ (symmetrically), accepting with probability $$\n    \\exp\\left\\{-\\frac{\\alpha_{t}}{m} \\left[d\\left(r_{i}', \\rho_{t}\\right) - d\\left(r_{i,t},\\rho_{t}\\right)\\right]\\right\\}\n    $$\n:::\n\n## Beach data\n\n![](figures/beach_data.png)\n\n## Beach data\n\n```{webr-r}\nbeach_preferences\n```\n\n## Preparing for analysis\n\n- Compare `dim`:\n\n```{webr-r}\nbeach_data <- setup_rank_data(preferences = beach_preferences)\nget_transitive_closure(beach_data)\n```\n\n## Diagnostics\n\n```{webr-r}\nmod <- compute_mallows(\n  data = beach_data,\n  compute_options = set_compute_options(save_aug = TRUE)\n)\nassess_convergence(mod)\nassess_convergence(mod, parameter = \"rho\")\nassess_convergence(mod, parameter = \"Rtilde\")\n```\n\n\n## Posteriors\n\n```{webr-r}\nmod <- compute_mallows(\n  data = setup_rank_data(preferences = beach_preferences),\n  compute_options = set_compute_options(nmc = 5000, save_aug = TRUE)\n)\nburnin(mod) <- 2500\ncompute_consensus(mod)\nplot_top_k(mod, k = 3)\n```\n\n\n# Mixtures\n\n## Mixture modeling\n\n- Heterogeneous population:\n\n$$\\rho_{c}, \\alpha_{c}, ~c=1,\\dots,C$$\n\n- Cluster probabilities\n\n$$\\tau_{c}, ~ c=1,\\dots,C$$\n\n## Mixtures of Mallows models {.smaller}\n\nComplete ranking, C-component mixture:\n\n$$\np\\left(r | \\theta\\right) = \\sum_{c=1}^{C}\\frac{\\tau_{c} \\exp\\left\\{ - \\left(\\alpha_{c}/m\\right) d\\left(r, \\rho_{c}\\right)\\right\\}}{Z\\left(\\alpha_{c} \\right)} \n$$\n\nwith $\\theta = \\{\\alpha_{c}, \\rho_{c}, \\tau_{c}\\}_{c=1}^{C}$ and $\\sum_{c=1}^{C}\\tau_{c}=1$.\n\n. . .\n\n-   Symmetric Dirichlet prior: $\\pi(\\tau_{1},\\dots,\\tau_{C}) \\propto \\prod_{c=1}^{C} \\tau_{c}^{\\psi-1}$.\n-   Cluster labels $z_{i} \\in \\{1,\\dots,C\\}$ multinomial with probabilities $\\tau_{c}$.\n\n## Markov chain Monte Carlo {.smaller}\n\n- Metropolis-within-Gibbs(?) algorithm:\n\n:::{.incremental}\n1. Sample $\\tau_{1}, \\dots, \\tau_{C} \\sim \\text{Dirichlet}(\\psi+n_{1},\\dots,\\psi+n_{C})$.\n2. Propose and accept/reject $\\alpha_{c}$, $\\rho_{c}$ for $c=1,\\dots,C$ with Metropolis-Hastings targeting\n$$\nP\\left(\\alpha_{1:C}, \\rho_{1:C} | z_{1:N}, \\text{data}\\right) \\propto \\\\\n\\left[\\prod_{c=1}^{C} \\alpha_{c}^{\\gamma_{c}-1} \\exp\\left\\{-\\lambda \\alpha_{c}\\right\\}  \\right] \\left[\\prod_{i=1}^{N} \\frac{\\exp\\left\\{-\\left(\\alpha_{z_{i}} /m\\right) d\\left(r_{i},\\rho_{z_{i}}\\right)\\right\\}}{Z\\left(\\alpha_{z_{i}}\\right)} \\right].\n$$\n3. Sample cluster labels $z_{i}$ multinomially with probabilities\n$$\np_{ic} = \\frac{\\tau_{c} \\exp\\left\\{-\\left(\\alpha_{c}/m\\right) d\\left(r_{i}, \\rho_{c}\\right)\\right\\}}{Z\\left(\\alpha_{c}\\right)}.\n$$\n:::\n\n## Sushi data\n\n```{webr-r}\nsushi_rankings\n```\n\n\n## Mixtures in BayesMallows\n\n```{r, eval=FALSE}\ncl <- makeCluster(7)\nmod <- compute_mallows_mixtures(\n  n_clusters = 1:7,\n  data = setup_rank_data(rankings = sushi_rankings),\n  compute_options = set_compute_options(include_wcd = TRUE),\n  cl = cl\n)\nstopCluster(cl)\n```\n\n## Mixtures in BayesMallows\n\n```{r, eval=FALSE}\nassess_convergence(mod)\n```\n\n![](figures/cluster_convergence.png)\n\n## How many clusters?\n\n```{r, eval=FALSE}\nburnin(mod) <- 300\nplot_elbow(mod)\n```\n\n![](figures/cluster_elbow.png)\n\n## Five-cluster model\n\n```{r}\nmod <- compute_mallows(\n  data = setup_rank_data(rankings = sushi_rankings),\n  model_options = set_model_options(n_clusters = 5)\n)\n```\n\n## Five-cluster model\n\n```{r}\nassess_convergence(mod)\n```\n\n```{r}\nburnin(mod) <- 500\n```\n\n\n## Posteriors for cluster weights\n\n```{r}\nplot(mod, parameter = \"cluster_probs\")\n```\n\n## Where do I belong?\n\n```{r}\nplot(mod, parameter = \"cluster_assignment\")\n```\n\n## Cluster consensus {.smaller}\n\n```{r}\ncompute_consensus(mod) %>% \n  as_tibble() %>% \n  select(-cumprob) %>% \n  pivot_wider(names_from = cluster, values_from = item)\n```\n\n\n# Non-transitive pairwise preferences\n\n## Inconsistencies\n\n@crispinoBayesianMallowsApproach2019 considers the case where pairwise preferences are inconsistent, e.g.,\n\n$$\n1 \\prec 2, 2 \\prec 3, 3 \\prec 1\n$$\n\n\n```{webr-r}\nprefs <- data.frame(\n  assessor = 1, bottom_item = c(1, 2, 3), top_item = c(2, 3, 1)\n)\nprepared <- setup_rank_data(preferences = prefs)\nget_transitive_closure(prepared)\n```\n\n## Inconsistent rankings\n\n@crispinoBayesianMallowsApproach2019:\n\n- Assume a truth $\\rho_{c}$ exists.\n- Inconsistencies are due to errors made by the assessor.\n- Introduce an error parameter.\n\n## Sounds data\n\n@barrettImpact3DSound2018:\n\n```{r}\nhead(sounds, 20)\n```\n\n\n## Inconsistent rankings in BayesMallows\n\n```{r}\ndat <- setup_rank_data(preferences = sounds)\nget_transitive_closure(dat)\n```\n\n## Inconsistent rankings in BayesMallows\n\n```{r}\nmod <- compute_mallows(\n  data = setup_rank_data(preferences = sounds),\n  compute_options = set_compute_options(nmc = 5000),\n  model_options = set_model_options(error_model = \"bernoulli\")\n)\n```\n\n## Convergence\n\n```{r, fig.height=5}\nassess_convergence(mod)\n```\n\n## Posteriors\n\n```{r}\nburnin(mod) <- 2000\nplot(mod, parameter = \"theta\")\n```\n\n\n# The end\n\n## References\n","srcMarkdownNoYaml":"\n\n## Learning goals\n\n- Bayesian Mallows model [@vitelliProbabilisticPreferenceLearning2017]\n- `BayesMallows` [@sorensenBayesMallowsPackageBayesian2020]\n- Computational algorithms [@vitelliProbabilisticPreferenceLearning2017]\n- Non-transitive preferences [@crispinoBayesianMallowsApproach2019]\n\n\n## R setup\n\n```{r, message=FALSE}\nlibrary(tidyverse)\ntheme_set(theme_bw())\ntheme_update(panel.grid = element_blank())\nlibrary(BayesMallows)\nlibrary(parallel)\n```\n\n# Bayesian Mallows model\n\n## Data-generating distribution\n\nRanking $r$ generated by\n\n$$\np\\left(r | \\theta\\right) = \\frac{\\exp\\left\\{ - \\left(\\alpha /m\\right) d\\left(r, \\rho\\right)\\right\\}}{Z\\left(\\alpha \\right)} \n$$\n\nwith support $\\mathcal{P}_{m}$ and $\\theta = \\{\\alpha, \\rho\\}$.\n\n## Data-generating distribution\n\n- Try out different $\\alpha$ and $\\rho$:\n\n```{webr-r}\nset.seed(12)\nsample_mallows(rho0 = 1:5, alpha0 = 2, n_samples = 4)\n```\n\n\n## Bayesian inference in a nutshell\n\n- Parameters of interest $\\theta$.\n\n- Prior distribution $\\pi(\\theta)$.\n\n- Likelihood $p(\\text{data} | \\theta)$.\n\n. . .\n\n- Posterior \n\n$$\np(\\theta | \\text{data}) = \\frac{\\pi(\\theta) p(\\text{data} | \\theta)}{p(\\text{data})}\n$$ \n\n## Priors for scale parameter\n\n-   @crispinoBayesianMallowsApproach2019:\n\n$$\n\\pi\\left(\\alpha\\right) \\propto \\alpha^{\\gamma-1} \\exp\\{-\\lambda \\alpha\\}, ~ \\alpha \\in [0, \\infty)\n$$\n\n-   @vitelliProbabilisticPreferenceLearning2017, special case $\\gamma=1$.\n\n## Gamma prior\n\n$\\gamma$ is the *shape* and $\\lambda$ is the *rate*.\n\n```{r, echo=FALSE}\ncrossing(\n  alpha = seq(from = 0, to = 3, by = .1),\n  rate = c(.1, 1),\n  shape = c(1, 2)\n) %>% \n  mutate(prob = dgamma(alpha, rate = rate, shape = shape)) %>% \n  ggplot(aes(x = alpha, y = prob, group = interaction(rate, shape),\n             color = factor(rate), linetype = factor(shape))) +\n  geom_line() + \n  ggthemes::scale_color_colorblind() +\n  labs(color = \"Rate\", linetype = \"Shape\") + \n  xlab(expression(alpha)) + \n  ylab(\"Prior density\")\n```\n\n## Prior for modal ranking\n\n-   Uniform distribution on $\\mathcal{P}_{m}$ most natural.\n-   Example, all having prior mass 1/6:\n\n```{webr-r}\nlibrary(e1071)\npermutations(3)\n```\n\n## Posterior distributions {.smaller}\n\n::: incremental\n-   Prior: $\\pi(\\alpha, \\rho) \\propto \\alpha^{\\gamma-1} \\exp\\{-\\lambda \\alpha\\}$ with support $\\mathbb{R}_{+} \\times \\mathcal{P}_{m}$\n\n-   Likelihood $$\n    \\prod_{i=1}^{N} p(r_{i} | \\alpha, \\rho) = \\frac{\\exp\\left\\{-\\left(\\alpha/m\\right) \\sum_{i=1}^{N} d\\left(r_{i}, \\rho\\right)\\right\\}}{Z\\left(\\alpha\\right)^{N}}\n    $$\n\n-   Posterior $$\n    P(\\alpha, \\rho | \\text{data}) \\propto \\frac{\\alpha^{\\gamma-1}\\exp\\left\\{-\\left(\\alpha/m\\right) \\left[\\lambda +\\sum_{i=1}^{N} d\\left(r_{i}, \\rho\\right) \\right]\\right\\}}{Z\\left(\\alpha\\right)^{N}} \n    $$\n    with support $\\mathbb{R}_{+} \\times \\mathcal{P}_{m}$.\n:::\n\n# Computation part I\n\n## Metropolis-Hastings {.smaller}\n\nGoal: obtain samples from $p(\\theta | r_{1:N})$.\n\n::: incremental\n1.  Initialize by picking an initial state $\\theta_{0}$.\n2.  Iterate for $t=0,1,2,\\dots$\n    a.  *Generate* a random candidate $\\theta'$ from proposal distribution $g(\\theta' | \\theta_{t})$.\n    b.  Calculate acceptance probability $$\n         A\\left(\\theta', \\theta_{t}\\right) = \\text{min}\\left\\{1, \\frac{p(\\theta')}{p(\\theta_{t})}\\frac{g(\\theta_{t}|\\theta')}{g(\\theta' | \\theta_{t})}\\right\\} \n         $$\n    c.  Set $\\theta_{t+1}=\\theta'$ with probability $A(\\theta',\\theta_{t})$. Otherwise set $\\theta_{t+1} = \\theta_{t}$.\n:::\n\n. . .\n\nUnder certain assumptions the collection $\\{\\theta_{0},\\theta_{1},\\dots\\}$ will approximate a sample from $p(\\theta)$.\n\n## Metropolis-Hastings for Mallows {.smaller}\n\n::: incremental\n-   Parameters $\\alpha$ and $\\rho$ can be dealt with one at a time.\n-   Acceptance probability $A(\\rho',\\rho_{t})$ for proposal $\\rho'$: $$\n    \\text{min}\\left\\{1, \\exp\\left\\{-\\left(\\alpha_{t}/m\\right) \\left[d\\left(r_{i},\\rho'\\right) - d\\left(r_{i},\\rho_{t}\\right)\\right]\\right\\} \\frac{g\\left(\\rho_{t}|\\rho'\\right)}{g\\left(\\rho'|\\rho_{t}\\right)}\\right\\}\n    $$\n-   Acceptance probability $A(\\alpha',\\alpha_{t})$ for proposal $\\alpha'$: $$\n    \\text{min}\\left\\{1, \\frac{\\left(\\alpha'\\right)^{\\gamma-1} Z\\left(\\alpha_{t}\\right)^{N}}{\\alpha_{t}^{\\gamma-1} Z\\left(\\alpha'\\right)^{N}} \\exp\\left\\{-\\frac{\\alpha'-\\alpha_{t}}{m}\\left[\\lambda+\\sum_{i=1}^{N}d\\left(r_{i},\\rho_{t}\\right)\\right]\\right\\}  \\frac{g\\left(\\alpha_{t} | \\alpha'\\right)}{g\\left(\\alpha'|\\alpha_{t}\\right)}\\right\\} \n    $$\n:::\n\n## Proposal for $\\alpha$ {.smaller}\n\n::: incremental\n-   $g(\\alpha'|\\alpha_{t})$ should have support on $\\mathbb{R}_{+}$ for efficiency.\n\n-   @vitelliProbabilisticPreferenceLearning2017 and `BayesMallows` use lognormal distribution $$\n    g\\left(\\alpha' | \\alpha_{t}\\right) \\propto \\frac{\\exp\\left\\{-\\left(\\ln \\alpha' - \\ln \\alpha_{t}\\right) / (2 \\sigma^{2})\\right\\}}{\\alpha' \\sigma}\n    $$\n\n-   Ratio becomes $$\n    \\frac{g\\left(\\alpha_{t} | \\alpha'\\right)}{g\\left(\\alpha' | \\alpha_{t}\\right)} = \\frac{\\alpha'}{\\alpha_{t}}\n    $$\n\n-   Acceptance probability $$\n    \\text{min}\\left\\{1, \\frac{\\left(\\alpha'\\right)^{\\gamma} Z\\left(\\alpha_{t}\\right)^{N}}{\\alpha_{t}^{\\gamma} Z\\left(\\alpha'\\right)^{N}} \\exp\\left\\{-\\frac{\\alpha'-\\alpha_{t}}{m}\\left[\\lambda+\\sum_{i=1}^{N}d\\left(r_{i},\\rho_{t}\\right)\\right]\\right\\} \\right\\} \n    $$\n:::\n\n## Proposal for $\\rho$\n\n::: incremental\n-   Key issue: $\\rho' \\in \\mathcal{P}_{m}$.\n\n-   Leap-and-shift [@vitelliProbabilisticPreferenceLearning2017] proposal; swap proposal [@crispinoBayesianMallowsApproach2019].\n\n-   Symmetry $g(\\rho' | \\rho_{t}) = g(\\rho_{t} | \\rho')$, always for swap, for leap-and-shift with leap size 1.\n\n-   Acceptance probability under symmetry $$\n    \\text{min}\\left\\{1, \\exp\\left\\{-\\frac{\\alpha_{t}}{m} \\left[d\\left(r_{i},\\rho'\\right) - d\\left(r_{i},\\rho_{t}\\right)\\right]\\right\\}\\right\\}\n    $$\n:::\n\n# Potato data\n\n---\n\n![](figures/potato.png){fig-align=\"center\"}\n\n## Potato data\n\n```{r}\npotato_visual\n```\n\n\n## Convergence diagnostics\n\n```{r}\ncl <- makeCluster(4)\nmod <- compute_mallows(\n  data = setup_rank_data(rankings = potato_visual), \n  compute_options = set_compute_options(nmc = 300), \n  cl = cl)\nstopCluster(cl)\n```\n\n## Convergence diagnostics\n\n```{r}\nassess_convergence(mod) + scale_color_discrete(guide = \"none\")\n```\n\n\n\n## Convergence diagnostics\n\n```{r, fig.align='center'}\ncl <- makeCluster(4)\nmod <- compute_mallows(\n  data = setup_rank_data(rankings = potato_visual), \n  compute_options = set_compute_options(nmc = 5000), \n  cl = cl)\nstopCluster(cl)\n```\n\n## Convergence diagnostics\n\n```{r}\nassess_convergence(mod) + scale_color_discrete(guide = \"none\")\n```\n\n## Convergence diagnostics\n\n```{r, message=TRUE}\nassess_convergence(mod, parameter = \"rho\")\n```\n\n# Studying the posteriors\n\n## Posteriors\n\n```{r}\nburnin(mod) <- 2500\nplot(mod)\n```\n\n## Posteriors\n\n```{r}\nplot(mod, parameter = \"rho\", items = 1:4)\n```\n\n## CP consensus\n\nCumulative probability consensus:\n\n- First select the item which has the maximum a posteriori marginal probability of being ranked 1st\n- Then select the item which has the maximum a posteriori marginal posterior probability of being ranked 1st or 2nd among the remaining ones.\n- etc.\n\n## CP consensus\n\n```{r}\ncompute_consensus(mod)\n```\n\n# Partial rankings and preferences\n\n## Top-3 rankings\n\n-   Top-3 rankings: $$\n    r_{i} = (\\cdot , 1, \\cdot, \\cdot, 3, 2)\n    $$\n\n-   Possible complete rankings: $$\n    (4, 1, 5, 6, 3, 2), (4, 1, 6, 5, 3, 2), \\\\\n    (5, 1, 4, 6, 3, 2), (5, 1, 6, 4, 3, 2), \\\\\n    (6, 1, 4, 5, 3, 2), (6, 1, 5, 4, 3, 2)\n    $$\n\n## Pairwise preferences\n\n-   Observation $(3 \\prec 2), (2 \\prec 1)$\n\n. . .\n\n```{webr-r}\nprefs <- data.frame(\n  assessor = 1, bottom_item = c(2, 3), top_item = c(1, 2))\nget_transitive_closure(\n  setup_rank_data(preferences = prefs, n_items = 4))\n```\n\n. . .\n\n-   Possible complete rankings (with 4 items) $$\n    (4, 1, 2, 3), (1, 4, 2, 3), (1, 2, 4, 3), (1, 2, 3, 4)\n    $$\n\n## Posteriors {.smaller}\n\n:::{.incremental}\n-   Partial ranking or pairwise preferences in $y_{i}$ generate a constraint set $\\mathcal{S}_{i}$.\n\n-   Marginal likelihood $$\n    \\prod_{i=1}^{N} p\\left(y_{i} | \\alpha, \\rho\\right) = \\frac{1}{Z\\left(\\alpha\\right)} \\prod_{i=1}^{N} \\sum_{r_{i} \\in \\mathcal{S}_{i}} \\exp\\left\\{-\\left(\\alpha /m\\right)  d\\left(r_{i}, \\rho\\right)\\right\\}\n    $$\n\n-   Marginal posterior $$\n    p\\left(\\alpha, \\rho | \\text{data}\\right) =  \\frac{\\alpha^{\\gamma -1 } \\exp\\left\\{-\\lambda \\alpha\\right\\}}{Z\\left(\\alpha\\right)} \\prod_{i=1}^{N} \\sum_{r_{i} \\in \\mathcal{S}_{i}} \\exp\\left\\{-\\left(\\alpha /m\\right) d\\left(r_{i}, \\rho\\right)\\right\\}\n    $$\n\n-   Complete data: special case with $\\mathcal{S}_{i} = \\{y_{i}\\}$.\n:::\n\n## Metropolis-Hastings\n\n:::{.incremental}\n-   Need to add sampling of $r_{i}$.\n-   Cost of $M$ iteration now becomes $\\mathcal{O}(NM)$, up from $\\mathcal{O}(M)$ with complete data.\n-   Proposing $r_{i}$ on $\\mathcal{S}_{i}$ (symmetrically), accepting with probability $$\n    \\exp\\left\\{-\\frac{\\alpha_{t}}{m} \\left[d\\left(r_{i}', \\rho_{t}\\right) - d\\left(r_{i,t},\\rho_{t}\\right)\\right]\\right\\}\n    $$\n:::\n\n## Beach data\n\n![](figures/beach_data.png)\n\n## Beach data\n\n```{webr-r}\nbeach_preferences\n```\n\n## Preparing for analysis\n\n- Compare `dim`:\n\n```{webr-r}\nbeach_data <- setup_rank_data(preferences = beach_preferences)\nget_transitive_closure(beach_data)\n```\n\n## Diagnostics\n\n```{webr-r}\nmod <- compute_mallows(\n  data = beach_data,\n  compute_options = set_compute_options(save_aug = TRUE)\n)\nassess_convergence(mod)\nassess_convergence(mod, parameter = \"rho\")\nassess_convergence(mod, parameter = \"Rtilde\")\n```\n\n\n## Posteriors\n\n```{webr-r}\nmod <- compute_mallows(\n  data = setup_rank_data(preferences = beach_preferences),\n  compute_options = set_compute_options(nmc = 5000, save_aug = TRUE)\n)\nburnin(mod) <- 2500\ncompute_consensus(mod)\nplot_top_k(mod, k = 3)\n```\n\n\n# Mixtures\n\n## Mixture modeling\n\n- Heterogeneous population:\n\n$$\\rho_{c}, \\alpha_{c}, ~c=1,\\dots,C$$\n\n- Cluster probabilities\n\n$$\\tau_{c}, ~ c=1,\\dots,C$$\n\n## Mixtures of Mallows models {.smaller}\n\nComplete ranking, C-component mixture:\n\n$$\np\\left(r | \\theta\\right) = \\sum_{c=1}^{C}\\frac{\\tau_{c} \\exp\\left\\{ - \\left(\\alpha_{c}/m\\right) d\\left(r, \\rho_{c}\\right)\\right\\}}{Z\\left(\\alpha_{c} \\right)} \n$$\n\nwith $\\theta = \\{\\alpha_{c}, \\rho_{c}, \\tau_{c}\\}_{c=1}^{C}$ and $\\sum_{c=1}^{C}\\tau_{c}=1$.\n\n. . .\n\n-   Symmetric Dirichlet prior: $\\pi(\\tau_{1},\\dots,\\tau_{C}) \\propto \\prod_{c=1}^{C} \\tau_{c}^{\\psi-1}$.\n-   Cluster labels $z_{i} \\in \\{1,\\dots,C\\}$ multinomial with probabilities $\\tau_{c}$.\n\n## Markov chain Monte Carlo {.smaller}\n\n- Metropolis-within-Gibbs(?) algorithm:\n\n:::{.incremental}\n1. Sample $\\tau_{1}, \\dots, \\tau_{C} \\sim \\text{Dirichlet}(\\psi+n_{1},\\dots,\\psi+n_{C})$.\n2. Propose and accept/reject $\\alpha_{c}$, $\\rho_{c}$ for $c=1,\\dots,C$ with Metropolis-Hastings targeting\n$$\nP\\left(\\alpha_{1:C}, \\rho_{1:C} | z_{1:N}, \\text{data}\\right) \\propto \\\\\n\\left[\\prod_{c=1}^{C} \\alpha_{c}^{\\gamma_{c}-1} \\exp\\left\\{-\\lambda \\alpha_{c}\\right\\}  \\right] \\left[\\prod_{i=1}^{N} \\frac{\\exp\\left\\{-\\left(\\alpha_{z_{i}} /m\\right) d\\left(r_{i},\\rho_{z_{i}}\\right)\\right\\}}{Z\\left(\\alpha_{z_{i}}\\right)} \\right].\n$$\n3. Sample cluster labels $z_{i}$ multinomially with probabilities\n$$\np_{ic} = \\frac{\\tau_{c} \\exp\\left\\{-\\left(\\alpha_{c}/m\\right) d\\left(r_{i}, \\rho_{c}\\right)\\right\\}}{Z\\left(\\alpha_{c}\\right)}.\n$$\n:::\n\n## Sushi data\n\n```{webr-r}\nsushi_rankings\n```\n\n\n## Mixtures in BayesMallows\n\n```{r, eval=FALSE}\ncl <- makeCluster(7)\nmod <- compute_mallows_mixtures(\n  n_clusters = 1:7,\n  data = setup_rank_data(rankings = sushi_rankings),\n  compute_options = set_compute_options(include_wcd = TRUE),\n  cl = cl\n)\nstopCluster(cl)\n```\n\n## Mixtures in BayesMallows\n\n```{r, eval=FALSE}\nassess_convergence(mod)\n```\n\n![](figures/cluster_convergence.png)\n\n## How many clusters?\n\n```{r, eval=FALSE}\nburnin(mod) <- 300\nplot_elbow(mod)\n```\n\n![](figures/cluster_elbow.png)\n\n## Five-cluster model\n\n```{r}\nmod <- compute_mallows(\n  data = setup_rank_data(rankings = sushi_rankings),\n  model_options = set_model_options(n_clusters = 5)\n)\n```\n\n## Five-cluster model\n\n```{r}\nassess_convergence(mod)\n```\n\n```{r}\nburnin(mod) <- 500\n```\n\n\n## Posteriors for cluster weights\n\n```{r}\nplot(mod, parameter = \"cluster_probs\")\n```\n\n## Where do I belong?\n\n```{r}\nplot(mod, parameter = \"cluster_assignment\")\n```\n\n## Cluster consensus {.smaller}\n\n```{r}\ncompute_consensus(mod) %>% \n  as_tibble() %>% \n  select(-cumprob) %>% \n  pivot_wider(names_from = cluster, values_from = item)\n```\n\n\n# Non-transitive pairwise preferences\n\n## Inconsistencies\n\n@crispinoBayesianMallowsApproach2019 considers the case where pairwise preferences are inconsistent, e.g.,\n\n$$\n1 \\prec 2, 2 \\prec 3, 3 \\prec 1\n$$\n\n\n```{webr-r}\nprefs <- data.frame(\n  assessor = 1, bottom_item = c(1, 2, 3), top_item = c(2, 3, 1)\n)\nprepared <- setup_rank_data(preferences = prefs)\nget_transitive_closure(prepared)\n```\n\n## Inconsistent rankings\n\n@crispinoBayesianMallowsApproach2019:\n\n- Assume a truth $\\rho_{c}$ exists.\n- Inconsistencies are due to errors made by the assessor.\n- Introduce an error parameter.\n\n## Sounds data\n\n@barrettImpact3DSound2018:\n\n```{r}\nhead(sounds, 20)\n```\n\n\n## Inconsistent rankings in BayesMallows\n\n```{r}\ndat <- setup_rank_data(preferences = sounds)\nget_transitive_closure(dat)\n```\n\n## Inconsistent rankings in BayesMallows\n\n```{r}\nmod <- compute_mallows(\n  data = setup_rank_data(preferences = sounds),\n  compute_options = set_compute_options(nmc = 5000),\n  model_options = set_model_options(error_model = \"bernoulli\")\n)\n```\n\n## Convergence\n\n```{r, fig.height=5}\nassess_convergence(mod)\n```\n\n## Posteriors\n\n```{r}\nburnin(mod) <- 2000\nplot(mod, parameter = \"theta\")\n```\n\n\n# The end\n\n## References\n"},"formats":{"revealjs":{"identifier":{"display-name":"RevealJS","target-format":"revealjs","base-format":"revealjs"},"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","filters":["webr"],"output-file":"presentation.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.6.42","auto-stretch":true,"webr":{"packages":["tidyverse","parallel","BayesMallows","combinat"],"autoload-packages":true},"title":"Bayesian Inference with the Mallows Model","author":"Øystein Sørensen","editor":"source","bibliography":["references.bib"],"theme":"serif"}}},"projectFormats":[]}